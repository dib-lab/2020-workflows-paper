## Workflow-Based Project Management

Computational project management is a learned skill that takes time to implement.
Biological analyses often span hundreds of steps and involve a myriad of decisions ranging from small-scale tool and parameter choices to larger-scale decisions around computational experimental design and statistical analyses.
It is rare (if not impossible) to build or find a workflow that analyzes your data from start to finish without testing, troubleshooting, and iteration.
Fortunately, with a little direction, workflow systems both simplify and improve computational project management.

### Systematically document your workflows

Workflow systems link each analysis step, so that downstream files are regenerated if upstream files and parameters change, as long as you re-run the workflow manager each time (steps will only be rerun if necessary).
In this way, the coded portions of workflows can be self-documenting, with each analysis step (and parameters) completely specified.
The simplest way to document your workflow, then, is to include as much of it as possible within the automated workflow framework.
However, this is limited in a few ways.
First, there may be portions of the workflow that you have not been able to automate, such as downloads of data from protected servers (e.g. containing protected identity information), or manual data and metadata cleaning steps.
Second, some steps may take a long time to rerun, so you may end up breaking your workflow into several independently-executed steps.
Third, even if the code and parameters are documented, it is critical to record the reasoning behind each particular analysis decision, so that you can assess the influence of each choice on the downstream results.

#### Use consistent, self-documenting names

For analysis workflows, it is useful to be able to look at a file and understand exactly which sample it belongs to, and which processing or analysis steps were used to generate it.
Using consistent and descriptive identifiers for your files, scripts, variables, workflows, projects, and even manuscripts helps keep your projects organized and interpretable for yourself and collaborators.
For workflow systems, this strategy can be implemented by tagging output files with a descriptive identifier for each analysis step, either in the filename or by placing output files within a descriptive output folder.
For example, the file shown in **Figure {@fig:filenaming}** has been preprocessed with a quality control trimming step.
For large workflows, placing results from each step of your analysis in isolated, descriptive folders can be essential for keeping your project workspace clean and organized.

![Since the number of files in data-intensive biology can quickly get out of hand, consistent file naming is especially important. It is useful to keep unique sample identification in the filename, often with a metadata file explaining the meaning of each unique descriptor. For analysis scripts, it can help to implement a numbering scheme, where the name of first file in the analysis begins with "00", the next with "01", etc. For output files, it can help to add a short, unique identifier to output files processed with each analysis step. This particular file is a RADsequencing fastq file of a fish species that has been preprocessed with a fastq quality trimming tool (courtesy of Shannon Joslin).](images/filenaming.svg){#fig:filenaming}

#### Store workflow metadata with the workflow

Developing biological analysis workflows can involve hundreds of small decisions: What parameters work best for each step?
Why did you use a certain reference file for annotation as compared with other available files?
How did you finally manage to get around the program or installation error?
All of these pieces of information contextualize your results and may be helpful when writing your manuscript.
Keeping information about these decisions in an intuitive and easily accessible place helps you find it when you need it.
To capitalize on the utility of version control systems described below, it is most useful to store this information in plain text files.
Each main directory should include notes on the data or scripts contained within, so that a collaborator could look into the directory and understand what to find there (especially since that "collaborator" is likely to be you, a few months from now!).
Code itself can contain documentation - you can include comments with the reasoning behind algorithm choice or include a link to the seqanswers post that helped you decide how to shape your differential expression analysis.
Larger pieces of information can be kept in "README" or notes documents kept alongside your code and other documents.
For example, a GitHub repository documenting the reanalysis of the Marine Microbial Eukaryote Transcriptome Sequencing Project uses a README alongside the code to document the workflow and digital object identifiers for data products [@url:https://github.com/dib-lab/dib-MMETSP; @doi:10.1093/gigascience/giy158].
While this particular strategy cannot be automated, it is critical for interpreting the final results of your workflow.

#### Document data and analysis exploration using computational notebooks

Computational notebooks allow users to combine narrative, code, and code output (e.g. visualizations) in a single location, enabling the user to conduct analysis and visually assess the results in a single file (see **Figure @fig:nb_figure**).
These notebooks allow for fully documented iterative analysis development, and are particularly useful for data exploration and developing visualizations prior to integration into a workflow or as a report generated by a workflow that can be shared with collaborators.

![**Examples of computational notebooks.** Computational notebooks allow the user to mix text, code, and results in one document.
**A** A shows an RMarkdown document viewed in the RStudio integrated development environment, while **B** shows a rendered HTML file produced by knitting the RMarkdown document [@url:https://rmarkdown.rstudio.com/].
**C** A Jupyter Notebook, where code, text, and results are rendered inline as each code chunk is executed  [@doi:10.3233/978-1-61499-649-1-87].
The second grey chunk is a raw markdown chunk with text that will be rendered inline when executed.
Both notebooks generate a histogram of a metadata feature, number of generations, from a long-term evolution experiment with *Escherichia coli* [@doi:10.1038/nature18959].
Computational notebooks facilitate sharing by packaging narrative, code, and visualizations together.
Computational notebooks can be packaged with tools like Binder [@doi:10.25080/Majora-4af1f417-011].
Binder makes a GitHub repository executable, using package management systems and docker to build reproducible and executable software environments specified in the repository.
Binders can be shared with collaborators (or students in a classroom setting), and analysis and visualization can be ephemerally reproduced or altered from the code provided in computational notebooks.  
](images/nb_figure.png){#fig:nb_figure}


#### Visualize your workflow

Visual representations can help illustrate the connections in a workflow and improve the readability and reproducibility of your project. At the highest level, flowcharts that detail relationships between steps of a workflow can help provide big-picture clarification, especially when the pipeline is complicated.
For individual steps, a graphical representation of the output can show the status of the project or provide insight on additional analyses that should be added. For example, **Figure {@fig:sgc_workflow}** illustrates a workflow visualization modified from a graph produced by the workflow software Snakemake [@doi:10.1101/462788].

![A directed acyclic graph (DAG) that illustrates connections between all steps of a sequencing data analysis workflow. Each box represents a step in the workflow, while lines connect sequential steps.
The DAG shown in this figure illustrates a real bioinformatics workflow and was generated by modifying the default Snakemake workflow DAG [@doi:10.1101/462788].
The colors represent arms of the workflow that achieve a final result, such as a multiple sequence alignment of a protein of interest.
While the workflow is complex, it is coordinated by a workflow system, alleviating the need for a user to manage file interdependencies.](images/hu_dag.png){#fig:sgc_workflow}

### Version control your project

As your project develops, version control allows you to keep track of changes over time.
You may already do this in some ways, perhaps with frequent hard drive backups or by manually saving different versions of the same file  - e.g. by appending the date to a script name or appending "version_1" or "version_FINAL" to a manuscript draft.
For computational workflows, using version control systems such as Git or Mercurial can be used to properly keep track of all changes over time, even across multiple systems, scripting languages, and project contributors (see **Figure {@fig:version_control}**).
If a key piece of a workflow inexplicably stops working, good version control can allow you to rewind in time and identify differences from when the pipeline worked to when it stopped working.

![**Version Control** Version control systems (e.g. Git, Mercurial) work by storing incremental differences in files from one saved version ("commit") to the next. To visualize the differences between each version, text editors such as Atom and online services such as GitHub, GitLab and Bitbucket use red highlight to denote deletions, and green highlighting to denote additions. In this trivial example, a typo in version 1 (in red) was corrected (green). These systems are extremely useful for code and manuscript development, as it is possible to return to the snapshot of any saved version. This means that version control systems save you from accidental deletions, preserve code you thought you no longer needed, and preserve a record of project changes over time.](images/version_control.svg){#fig:version_control}

Version control systems also facilitate code and data availability and reproducibility for publication.
For example, to ensure the correct version of the code is preserved, you can create a "release", a snapshot of the current code and files in a GitHub repository.
You can then generate a digital object identifier (DOI) for that release using Zenodo and make it available to reviewers and beyond (see "sharing" section, below).

### Share your workflow and analysis code

Sharing your workflow code with collaborators, peer reviewers, and scientists seeking to use a similar method can foster discussion and review of your analysis.
Sticking to a clear documentation strategy, using a version control system, and packaging your code in notebooks or as a workflow prepare them to be easily shared with others.
To go one step further, you can package your code with a tool like Binder, Whole Tale, or Shiny apps, which run the code on cloud computers in environments identical to those in which the original computation was performed (**Figure @fig:nb_figure**, **Figure @fig:interactiveviz**) [@doi:10.25080/Majora-4af1f417-011; @doi:10.1016/j.future.2017.12.029].
These tools substantially reduce overhead associated with interacting with someones code base and data, and in doing so, make it fast and easy to rerun portions of the analysis, check accuracy, or even tweak the analysis to produce new results. If you choose to share your code and workflows publicly, you will also help contribute to the growing resource of biological analyses available for your chosen workflow system.

![Interactive vizualizations facilitate sharing and repeatability.
**A** Interactive vizualization dashboard in the Pavian Shiny app for metagenomic analysis [@url:https://fbreitwieser.shinyapps.io/pavian/; @doi:10.1093/bioinformatics/btz715].
Shiny allows you to build interactive web pages using R code.
Data is manipulated  by R code in real-time in a web page, producing analysis and visualizations of a data set.
Shiny apps can contain user-specifiable parameters, allowing a user to control visualizations or analyses. As seen above, sample "PT1" is selected, and taxonomic ranks class and order are excluded.
Shiny apps allow collaborators who may or may not know R to change R visualisations to fit their interests.   
**B** Plotly heatmap of transcriptional profiling in human brain samples [@url:https://plotly.com/python/v3/ipython-notebooks/bioinformatics/#4-heatmap-of-gene-expression].
Hovering over a cell in the heatmap displays the sample names from the x and y axis, as well as the intensity value.
Plotting tools like plotly and vega-lite produce single interactive plots that can be shared with collaborators or integrated into websites [@url:https://plotly.com/; @doi:10.1109/TVCG.2016.2599030].
Interactive visualizations are also helpful in exploratory data analysis.
](images/interactive_viz.png){#fig:interactiveviz}


### Getting started developing workflows

In our experience, the best way to have your workflow system work _for_ you is to include as much of your analysis as possible within the automated workflow framework, use self-documenting names, include analysis visualizations, and keep rigorous documentation alongside your workflow that enables you to understand each decision and entirely reproduce any manual steps. 
Some of the tools discussed above will inevitably change over time, but these principles apply broadly and will help you design clear, well-documented, and reproducible analyses. 
Ultimately, you'll need to experiment with the ways that work for you -- what is most important is to develop a clear set of strategies and implement them tenaciously. 
Here are a few practical tips to get started.

**Start with working code**
The best way to develop your own workflow analysis is to start from working code: either from the workflow tutorials or code sharing websites like GitHub, GitLab, and Bitbucket.
If a workflow is available through Binder, you can test and experiment with workflow modification on Binder's cloud system, without needing to install a workflow manager or software management tool.
When you're building a workflow for the first time, choose code in official repositories or reasonably well-used that provides sample data that can be run to verify the analysis works.
The "Workflows and Software Management" Section links to a number of official repositories containing tutorials and example biological analysis workflows.

**Test with subsampled data**
After verifying your chosen example workflow is functional, try running it with your own data or some public data related to your species or condition of interest (see **Table {@tbl:seq_resources}**)
To save yourself time, energy, and computational resources, first create a small test subset of the data.
For example, if working with FASTQ data, you can subsample the first million lines of a file (first 250k reads) by running:

`head -n 1000000 FASTQ_FILE.fq > test_fastq.fq`

While there are many more sophisticated ways to subsample reads, this technique should be sufficient for testing each step of a workflow prior to running your full dataset.

**Document your process** Write documentation in plain text, so your notes files can be saved under version control with your workflow. We recommend using Markdown language for your notes so they can include helpful headings, code formatting, and embedded images. We recommend using software with visual text previewing such as Hackmd or Atom [@url:https://hackmd.io/, @url:https://atom.io/].

**Develop your workflow**
Now that you have the workflow running on new data, you can begin to modify a workflow step to meet your needs.
Run each modified step on your subsampled data, checking that the output files look correct.
Keep the tool documentation and tutorials on hand; as with any language, remembering workflow-specific syntax takes time and practice.

**Back up early and often**
Now that you've written new code, the first thing to do is back up your changes in an online repository such as GitHub, GitLab, or Bitbucket.
These services support drag-and-drop interaction: after creating and naming a project repository for your code, you can upload files by dragging and dropping on the web browser.
Data backup will be discussed in the next section, "Practical considerations for workflow-enabled biology".

**Scale up your workflow**
Bioinformatic tools vary in the resources they require: some analysis steps are compute-intensive, other steps are memory intensive, and still others will have large intermediate storage needs.
If using high-performance computing system, you will need to request resources for running your pipeline, often provided as a simultaneous execution limit or purchased by your research group on a cost-per-compute basis.
Workflow systems provide built-in tools to monitor resource usage for each step.
Turn on this reporting according to workflow documentation and record the resources required for running each tool on a full-size single sample.
Use these estimates to set appropriate resource limits for each step when executing the workflow on your remaining samples.

**Find a community and ask for help when you need it**
If there are local user groups for your workflow language, try to get involved with the community.
When you are first learning, help from more advanced users can save you hours of frustration.
After you've progressed, providing that same help to new users can help you cement the syntax in your mind and tackle more advanced uses.
If no local community is available, look online for forums related to your workflow language.
These workflow systems have been enthusiastically adopted by the open science community, and as a consequence, there is a critical mass of tutorials and open access code, code discussion on forums and via social media, particularly twitter.
Be respectful of people's time and energy: post in the relevant workflow forums only when you've hit a stopping point you're unable to work through.
